{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KG-M1GRVYhlP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "#from scipy.misc import imread\n",
    "from imageio import imread\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-dGQaj8wYhlh"
   },
   "source": [
    "# ADD content\n",
    "# Loading dataset for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wx9VvGzZYhlo"
   },
   "outputs": [],
   "source": [
    "train_folder = \"C:/Users/Thai Ngoc/Desktop/Fellowship.ai/One shot learning/omniglot-master/data/images_background/\"\n",
    "evaluation_folder = 'C:/Users/Thai Ngoc/Desktop/Fellowship.ai/One shot learning/omniglot-master/data/images_evaluation/'\n",
    "hyperparameter1_folder = 'C:/Users/Thai Ngoc/Desktop/Fellowship.ai/One shot learning/omniglot-master/data/images_background_small1'\n",
    "hyperparameter2_folder = 'C:/Users/Thai Ngoc/Desktop/Fellowship.ai/One shot learning/omniglot-master/data/images_background_small2'\n",
    "save_path = 'C:/Users/Thai Ngoc/Desktop/Fellowship.ai/One shot learning/omniglot-master/data/data_save/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ct1mWJTYYhlw"
   },
   "outputs": [],
   "source": [
    "# Load dataset with input path folder (background and evaluation). Return a list of Alphabet and the corresponding name\n",
    "def load_dataset(path_dict):\n",
    "    list_alphabet = list()\n",
    "    list_name = list()\n",
    "    #Load each alphabet in the folder\n",
    "    for alphabet in os.listdir(path_dict):\n",
    "        #print(\"Loading alphabet: \" + alphabet)\n",
    "        list_name.append(alphabet)\n",
    "        alphabet_images = []\n",
    "        alphabet_path = os.path.join(path_dict, alphabet)\n",
    "        # Load each letter in the alphabet\n",
    "        for letter in os.listdir(alphabet_path):\n",
    "            letter_path = os.path.join(alphabet_path, letter)\n",
    "            letter_images = []\n",
    "            #Load 20 images for each letter\n",
    "            for filename in os.listdir(letter_path):\n",
    "                image_path = os.path.join(letter_path, filename)\n",
    "                image = imread(image_path)\n",
    "                image = np.expand_dims(image, axis=-1)\n",
    "                letter_images.append(image)                \n",
    "            letter_images = np.array(letter_images)\n",
    "            alphabet_images.append(letter_images)\n",
    "        alphabet_images = np.array(alphabet_images)\n",
    "        #print(\"shape of alphabet\", alphabet_images.shape)\n",
    "        list_alphabet.append(alphabet_images)\n",
    "    \n",
    "    return list_alphabet, list_name\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Moop3jOGYhmB"
   },
   "outputs": [],
   "source": [
    "X_train, name_train = load_dataset(train_folder)\n",
    "X_hyper1, name_hyper1 = load_dataset(hyperparameter1_folder)\n",
    "X_hyper2, name_hyper2 = load_dataset(hyperparameter2_folder)\n",
    "X_eval, name_eval = load_dataset(evaluation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHlb3Y7mYhmJ"
   },
   "outputs": [],
   "source": [
    "#Save datasets into file for next training  or loading on google colab\n",
    "\n",
    "with open(os.path.join(save_path,\"train.pickle\"), \"wb\") as f:\n",
    "    pickle.dump((X_train, name_train),f)\n",
    "    \n",
    "with open(os.path.join(save_path,\"hyper1.pickle\"), \"wb\") as f:\n",
    "    pickle.dump((X_hyper1, name_hyper1),f)\n",
    "    \n",
    "with open(os.path.join(save_path,\"hyper2.pickle\"), \"wb\") as f:\n",
    "    pickle.dump((X_hyper2, name_hyper2),f)\n",
    "    \n",
    "with open(os.path.join(save_path,\"evaluation.pickle\"), \"wb\") as f:\n",
    "    pickle.dump((X_eval, name_eval),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20262,
     "status": "ok",
     "timestamp": 1569885809669,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "1MzYIv45Yx0z",
    "outputId": "7ed78a76-9aff-4c06-e372-5e9f624cb63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaCxJvYUYhmP"
   },
   "outputs": [],
   "source": [
    "#Load datasets from saved file (do not need load from directories)\n",
    "save_path = '/content/drive/My Drive/data'\n",
    "with open(os.path.join(save_path, \"train.pickle\"), \"rb\") as f:\n",
    "    (X_train, name_train) = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(save_path, \"hyper1.pickle\"), \"rb\") as f:\n",
    "    (X_hyper1, name_hyper1) = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(save_path, \"hyper2.pickle\"), \"rb\") as f:\n",
    "    (X_hyper2, name_hyper2) = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(save_path, \"evaluation.pickle\"), \"rb\") as f:\n",
    "    (X_eval, name_eval) = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1569814772824,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "NyRtRCSmYhmV",
    "outputId": "6ec52590-7033-4c7b-f526-663e4160096e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 20, 105, 105, 1)\n"
     ]
    }
   ],
   "source": [
    "print((X_train[1]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1569582559125,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "KVmzks0xYhmc",
    "outputId": "9aaff920-66ba-4153-caeb-2510e663acac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Angelic', 'Atemayar_Qelisayer', 'Atlantean', 'Aurek-Besh', 'Avesta', 'Ge_ez', 'Glagolitic', 'Gurmukhi', 'Kannada', 'Keble', 'Malayalam', 'Manipuri', 'Mongolian', 'Old_Church_Slavonic_(Cyrillic)', 'Oriya', 'Sylheti', 'Syriac_(Serto)', 'Tengwar', 'Tibetan', 'ULOG']\n"
     ]
    }
   ],
   "source": [
    "print(name_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqrohXBEYhmk"
   },
   "source": [
    "# Construct model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3ylxPsKYhmo"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(shape, dtype=None):\n",
    "    return tf.keras.backend.random_normal(shape, mean=0, stddev=0.01, dtype=dtype)\n",
    "def initialize_bias(shape, dtype=None):\n",
    "    return tf.keras.backend.random_normal(shape, mean=0.5, stddev=0.01, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ5kP0mkYhmv"
   },
   "outputs": [],
   "source": [
    "def siamese_model(input_shape):\n",
    "    input_left = tf.keras.Input(input_shape)\n",
    "    input_right = tf.keras.Input(input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, 10, activation='relu', input_shape=input_shape,\n",
    "                                     kernel_initializer=initialize_weights, bias_initializer=initialize_bias, \n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(2e-4)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2))\n",
    "    model.add(tf.keras.layers.Conv2D(128, 7, activation='relu',\n",
    "                                    kernel_initializer=initialize_weights, bias_initializer=initialize_bias,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(2e-4)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2))\n",
    "    model.add(tf.keras.layers.Conv2D(128,4, activation='relu',\n",
    "                                    kernel_initializer=initialize_weights, bias_initializer=initialize_bias,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(2e-4)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2))\n",
    "    model.add(tf.keras.layers.Conv2D(256, 4, activation='relu',\n",
    "                                    kernel_initializer=initialize_weights, bias_initializer=initialize_bias,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(2e-4)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='sigmoid',\n",
    "                                  kernel_initializer=initialize_weights, bias_initializer=initialize_bias,\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(1e-3)))\n",
    "    encode_left = model(input_left)\n",
    "    encode_right = model(input_right)\n",
    "    L1_layer = tf.keras.layers.Lambda(lambda tensor: tf.keras.backend.abs(tensor[0]-tensor[1]))\n",
    "    L1_distance = L1_layer([encode_left, encode_right])\n",
    "    L1_distance_dropout = tf.keras.layers.Dropout(0.4)(L1_distance)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid',\n",
    "                                  kernel_initializer=initialize_weights,bias_initializer=initialize_bias,\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(1e-3))(L1_distance)\n",
    "    siamese_cnn = tf.keras.Model(inputs=[input_left, input_right], outputs=output)\n",
    "    return siamese_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qsn_fZRYYhm1"
   },
   "outputs": [],
   "source": [
    "model = siamese_model((105,105,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1620,
     "status": "ok",
     "timestamp": 1569444248910,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "cGc2qgwpYhm8",
    "outputId": "7b738752-2fd5-46e2-fa0a-7be47d478c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2229,
     "status": "ok",
     "timestamp": 1569867720678,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "G-qe9_VmYhnA",
    "outputId": "8de19125-068f-483d-828a-51ac298ca5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18020310713358633849\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8838083554845084104\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2576655622763335523\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11330115994\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15611999570529470547\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzpJnx5GYhnG"
   },
   "source": [
    "# Get batch for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cByKnAerYhnI"
   },
   "outputs": [],
   "source": [
    "def generateOneTrial(data_type = \"train\"):\n",
    "    if (data_type=='train'):\n",
    "        X = X_train\n",
    "        name_class = name_train\n",
    "    if (data_type=='evaluation'):\n",
    "        X = X_eval\n",
    "        name_class = name_eval\n",
    "    if (data_type=='hyper1'):\n",
    "        X = X_hyper1\n",
    "        name_class = name_hyper1\n",
    "    if (data_type=='hyper2'):\n",
    "        X = X_hyper2\n",
    "        name_class = name_hyper2\n",
    "     \n",
    "    data = []\n",
    "    len_alpha = len(X)  # Number of alphabets in training set   \n",
    "    alph = np.random.randint(len_alpha) # Choose randomly  an alphabet\n",
    "    len_char = X[alph].shape[0] # Number of characters in the alphabet\n",
    "    characters = np.random.choice(len_char, size =2, replace = False) # Choose randomly two distint character in the alphabet\n",
    "    len_example = X[alph].shape[1] # Number of examples for each character\n",
    "    examples = np.random.choice(len_example, size = 2, replace = False) # Choose randomly two distint drawers\n",
    "    img_true = X[alph][characters[0]][examples[0]]\n",
    "    img_positive = X[alph][characters[0]][examples[1]]\n",
    "    img_negative = X[alph][characters[1]][examples[0]]\n",
    "    #data.append([img_true, img_positive, img_negative]) \n",
    "    data.append(img_true)\n",
    "    data.append(img_positive)\n",
    "    data.append(img_negative)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAmeytTBYhnN"
   },
   "outputs": [],
   "source": [
    "data = generateOneTrial('train')\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1093,
     "status": "ok",
     "timestamp": 1569399626957,
     "user": {
      "displayName": "Nguyen Thai Ngoc",
      "photoUrl": "",
      "userId": "01879154502770230665"
     },
     "user_tz": -120
    },
    "id": "LIQasnbCYhnU",
    "outputId": "02d7460d-8a6a-4a95-8255-74073074bf23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 105, 105, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIK9ugQrYhnZ"
   },
   "outputs": [],
   "source": [
    "def batch_generate(size, data_type = 'train'):\n",
    "    w, h = X_train[1].shape[2], X_train[1].shape[3]\n",
    "    data = [np.zeros((size*2, h, w,1)) for i in range(2)]\n",
    "    label = np.zeros((size*2,))\n",
    "    for i in range(size):\n",
    "        trial = generateOneTrial(data_type)\n",
    "        trial_true = trial[0]\n",
    "        trial_positive = trial[1]\n",
    "        trial_negative = trial[2]\n",
    "        data[0][2*i] = trial_true\n",
    "        data[1][2*i] = trial_positive\n",
    "        data[0][2*i+1] = trial_true\n",
    "        data[1][2*i+1] = trial_negative\n",
    "    for i in range(size):\n",
    "        label[i*2+1] = 1\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZ0sx4D0Yhng"
   },
   "outputs": [],
   "source": [
    "data, label = batch_generate(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1569341112470,
     "user": {
      "displayName": "Nguyen Thai Ngoc",
      "photoUrl": "",
      "userId": "01879154502770230665"
     },
     "user_tz": -120
    },
    "id": "HWZmm503Yhnk",
    "outputId": "f627f6fc-aa1c-44a4-e9dd-f5cef0385be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 105, 105, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1349,
     "status": "ok",
     "timestamp": 1569341116514,
     "user": {
      "displayName": "Nguyen Thai Ngoc",
      "photoUrl": "",
      "userId": "01879154502770230665"
     },
     "user_tz": -120
    },
    "id": "82lommbMYhnq",
    "outputId": "1802fcd3-579f-4159-bf6d-7719cba4b5e9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAACmCAYAAAAVgMyZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1JIkFcxCLUlSwf4fVrhzMSVQsKwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 3\n",
    "rows = 1\n",
    "image1=data[0][10]\n",
    "image2=data[1][10]\n",
    "image3=data[1][5]\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(image1.reshape(105,105))\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(image2.reshape(105,105))\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(image3.reshape(105,105))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mjOee846sG0"
   },
   "outputs": [],
   "source": [
    "def generate_one_shot_evaluation(N_way=20, data_type = \"evaluation\"):\n",
    "    if (data_type == \"train\"):\n",
    "      X = X_train\n",
    "    else:\n",
    "      X = X_eval\n",
    "    len_val = len(X)\n",
    "    while True:\n",
    "      alph = np.random.randint(len_val) # Choose randomly one alphabet\n",
    "      len_characters = X[alph].shape[0] # Number of characters in the alphabet\n",
    "      if (len_characters>=N_way):\n",
    "        break    \n",
    "    characters = np.random.choice(len_characters, size=N_way, replace = False) # Choose N_way distint characters in the alphabet\n",
    "    len_example = X[alph].shape[1] # Number of examples for each character\n",
    "    examples = np.random.choice(len_example, size = 2, replace = False) # Choose randomly two distint drawers\n",
    "    train_img = []\n",
    "    test_img = []\n",
    "    for i in range(20):\n",
    "        test_img.append(X[alph][characters[i]][examples[0]])\n",
    "        train_img.append(X[alph][characters[i]][examples[1]])\n",
    "    test_img = np.array(test_img)\n",
    "    train_img = np.array(train_img)\n",
    "    return test_img, train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14222,
     "status": "ok",
     "timestamp": 1569399655340,
     "user": {
      "displayName": "Nguyen Thai Ngoc",
      "photoUrl": "",
      "userId": "01879154502770230665"
     },
     "user_tz": -120
    },
    "id": "Vu4bU9Ov8Mkq",
    "outputId": "a46def1d-0ec4-407e-8356-f22339ae5ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "n_accuracy = 0\n",
    "for i in range(10):  \n",
    "  test_img, train_img = generate_one_shot_evaluation(data_type='train')\n",
    "  for j in range(20):\n",
    "    test_img_N_way = np.array([test_img[j] for k in range(20)])\n",
    "    data_test = [test_img_N_way, train_img]\n",
    "    predict_value = model.predict(data_test)\n",
    "    if (j==np.argmin(predict_value)):\n",
    "      n_accuracy = n_accuracy+1\n",
    "accuracy = n_accuracy/(10*20)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BvVzQVz66Wy"
   },
   "outputs": [],
   "source": [
    "N_way = 20\n",
    "def test_one_shot(iteration, data_type = 'evaluation'):\n",
    "    n_accuracy = 0\n",
    "    for i in range(iteration):\n",
    "        test_img, train_img = generate_one_shot_evaluation(20, data_type)\n",
    "        for k in range(20):\n",
    "            test_image_N_way = np.array([test_img[k] for m in range(20)])\n",
    "            data_train = [test_image_N_way, train_img]\n",
    "            predict_value = model.predict(data_train)\n",
    "            if (k==np.argmin(predict_value)):\n",
    "              n_accuracy+=1              \n",
    "    accuracy = n_accuracy/(iteration*N_way)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8302,
     "status": "ok",
     "timestamp": 1569444131324,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "enn3tisvA_f1",
    "outputId": "b6c0cf2b-c7d6-4ff3-9e8d-02cb8061e5e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685\n"
     ]
    }
   ],
   "source": [
    "print(test_one_shot(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P7ReG1TNc7a-"
   },
   "source": [
    " **TRAINING MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NEVdnbqYhnx"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.load_weights(os.path.join(save_path, 'weights.best.h5'))\n",
    "t_start = time.time()\n",
    "for i in range(200000):\n",
    "    data, label = batch_generate(16)\n",
    "    loss = model.train_on_batch(data, label)    \n",
    "    if i%2000==0:\n",
    "        t_end = time.time()\n",
    "        print(\"Time  for {0} iteration: {1}\".format(i, (t_end-t_start)/60))\n",
    "        print('Loss: ', loss)\n",
    "        model.save_weights(os.path.join(save_path, 'weights.best.h5'))\n",
    "        acc = test_one_shot(20)\n",
    "        print(\"Test accuracy: \", acc)\n",
    "#model.save_weights(os.path.join(save_path, 'weights.best.h5')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28306,
     "status": "ok",
     "timestamp": 1569468926985,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "NfkyxbmHYhn_",
    "outputId": "49b61460-8f2b-4f59-937d-d261b606e23e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6395\n"
     ]
    }
   ],
   "source": [
    "acc = test_one_shot(100, data_type=\"evaluation\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wk0dTNj9R_pz"
   },
   "source": [
    "**Model with Triplet loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oBA5S6HYhoE"
   },
   "outputs": [],
   "source": [
    "def model_triplet_example(input_shape):\n",
    "    input_true = tf.keras.Input(input_shape)\n",
    "    input_positive = tf.keras.Input(input_shape)\n",
    "    input_negative = tf.keras.Input(input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Conv2D(64, 10, activation='relu', input_shape=input_shape,\n",
    "                                     kernel_initializer=initialize_weights, bias_initializer=initialize_bias, \n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(2e-4)))\n",
    "    #model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D(2))\n",
    "    model.add(tf.keras.layers.Conv2D(128, 7, activation='relu',\n",
    "                                    kernel_initializer=initialize_weights, bias_initializer=initialize_bias,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(1e-2)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2))\n",
    "    model.add(tf.keras.layers.Conv2D(128,4, activation='relu',\n",
    "                                    kernel_initializer=initialize_weights, bias_initializer=initialize_bias,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(1e-2)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2))\n",
    "    model.add(tf.keras.layers.Conv2D(256, 4, activation='relu',\n",
    "                                    kernel_initializer=initialize_weights, bias_initializer=initialize_bias,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(1e-2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='sigmoid',\n",
    "                                  kernel_initializer=initialize_weights, bias_initializer=initialize_bias,\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(1e-4)))\n",
    "    #model.add(tf.keras.layers.Dropout(0.3))\n",
    "    emb_true = model(input_true)\n",
    "    emb_pos = model(input_positive)\n",
    "    emb_neg = model(input_negative)\n",
    "    dist_layer = tf.keras.layers.Lambda(lambda tensor: tf.abs(tensor[0]-tensor[1]), name = 'distance')\n",
    "    dist_pos = dist_layer([emb_true, emb_pos])\n",
    "    dist_neg = dist_layer([emb_true, emb_neg])\n",
    "    last_layer = tf.keras.layers.Dense(1, activation='sigmoid', name ='last_layer_triplet')\n",
    "    pred_pos = last_layer(dist_pos)\n",
    "    pred_neg = last_layer(dist_neg)\n",
    "    loss_layer = tf.keras.layers.Lambda(lambda tensor: tf.square(tensor[0])+tf.square(1-tensor[1]))\n",
    "    loss = loss_layer([pred_pos, pred_neg])\n",
    "    triplet_model = tf.keras.Model(inputs=[input_true, input_positive, input_negative], outputs = loss)\n",
    "    return triplet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1569885912032,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "FEEkoVzRYhoK",
    "outputId": "43ee2a09-a1b2-4ab9-be30-631214b99089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 4096)         38947648    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "distance (Lambda)               (None, 4096)         0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "                                                                 sequential[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "last_layer_triplet (Dense)      (None, 1)            4097        distance[0][0]                   \n",
      "                                                                 distance[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           last_layer_triplet[0][0]         \n",
      "                                                                 last_layer_triplet[1][0]         \n",
      "==================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 38,951,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_triplet = model_triplet_example((105,105,1))\n",
    "model_triplet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LY3HHYDNYhoP"
   },
   "outputs": [],
   "source": [
    "def triplet_loss_example(y_true, y_pred):\n",
    "    pred_pos, pred_neg = y_pred[0], y_pred[1]\n",
    "    #loss = tf.square(pred_pos) + tf.square(1-pred_neg)\n",
    "    loss = tf.maximum(pred_pos-pred_neg+0.2, 0)\n",
    "    return loss\n",
    "def identity_loss_example(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFXBoByqSb1P"
   },
   "outputs": [],
   "source": [
    "optimizer_triplet = tf.keras.optimizers.Adam(lr = 0.0000003)\n",
    "model_triplet.compile(loss=identity_loss_example, optimizer=optimizer_triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaOoeiquTjsI"
   },
   "outputs": [],
   "source": [
    "def generate_batch_triplet(size, data_type = \"train\"):\n",
    "    w, h = X_train[1].shape[2], X_train[1].shape[3]\n",
    "    batch_triplet = [np.zeros((size,w,h,1)) for i in range(3)]\n",
    "    for i in range(size):\n",
    "        one_triplet = generateOneTrial(data_type=data_type)\n",
    "        batch_triplet[0][i] = one_triplet[0]\n",
    "        batch_triplet[1][i] = one_triplet[1]\n",
    "        batch_triplet[2][i] = one_triplet[2]\n",
    "    output = np.zeros((size,))\n",
    "    return batch_triplet, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSxu7WJLUwGv"
   },
   "outputs": [],
   "source": [
    "batch_triplet_trial, output = generate_batch_triplet(50, data_type = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 809745,
     "status": "ok",
     "timestamp": 1569886745606,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "T6zjo3RKU-3h",
    "outputId": "5157e8d5-d583-4b8d-f54a-0f159c764829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 with time 0.09773690303166707\n",
      "Loss:  0.0143231\n",
      "Accuracy: 0.704\n",
      "Best score at iteration 0 is 0.704\n",
      "Iteration 200 with time 2.8737351179122923\n",
      "Loss:  0.013851965\n",
      "Accuracy: 0.684\n",
      "Iteration 400 with time 5.499474442005157\n",
      "Loss:  0.014246955\n",
      "Accuracy: 0.688\n",
      "Iteration 600 with time 8.120214180151622\n",
      "Loss:  0.013879222\n",
      "Accuracy: 0.7025\n",
      "Iteration 800 with time 10.742629810174305\n",
      "Loss:  0.014509976\n",
      "Accuracy: 0.6865\n",
      "Best score 0.704\n",
      "Iteration 0\n"
     ]
    }
   ],
   "source": [
    "model_triplet.load_weights(os.path.join(save_path, 'weights.best_triplet_last.h5'))\n",
    "start_time = time.time()\n",
    "score = 0\n",
    "iteration_best = 0\n",
    "for i in range(1000):\n",
    "    batch_triplet_trial, output = generate_batch_triplet(32)\n",
    "    loss = model_triplet.train_on_batch(batch_triplet_trial, output)\n",
    "    if i%200 ==0:\n",
    "      end_time = time.time()\n",
    "      print('Iteration {} with time {}'.format(i, (end_time-start_time)/60))\n",
    "      print(\"Loss: \", loss)\n",
    "      acc_triplet = test_one_shot_triplet(100)\n",
    "      print('Accuracy:', acc_triplet)\n",
    "      if (score<acc_triplet):\n",
    "        print(\"Best score at iteration {} is {}\".format(i,acc_triplet))\n",
    "        model_triplet.save_weights(os.path.join(save_path, 'weights.best_triplet{}.h5'.format(i)))\n",
    "        score = acc_triplet\n",
    "        iteration_best = i\n",
    "model_triplet.save_weights(os.path.join(save_path, 'weights.best_triplet_last.h5'))\n",
    "print(\"Best score\", score)\n",
    "print(\"Iteration\", iteration_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiUZ1DxixHsw"
   },
   "outputs": [],
   "source": [
    "model_triplet.save_weights(os.path.join(save_path, 'weights.best_triplet_last.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hjBq7Q4ydNQ"
   },
   "outputs": [],
   "source": [
    "def test_one_shot_triplet(iteration, data_type = 'evaluation'):\n",
    "    n_accuracy = 0\n",
    "    for i in range(iteration):\n",
    "        test_img, train_img = generate_one_shot_evaluation(20, data_type)\n",
    "        for k in range(20):\n",
    "            test_image_N_way = np.array([test_img[k] for m in range(20)])\n",
    "            data_train = [train_img, test_image_N_way, train_img]\n",
    "            predict_value = model_triplet.predict(data_train)\n",
    "            if (k==np.argmin(predict_value)):\n",
    "              n_accuracy+=1              \n",
    "    accuracy = n_accuracy/(iteration*N_way)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 106945,
     "status": "ok",
     "timestamp": 1569852940484,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "9QoIj1T4YJiM",
    "outputId": "741eb11d-b47f-4ae9-98cd-f20f530b4835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693\n"
     ]
    }
   ],
   "source": [
    "model_triplet.load_weights(os.path.join(save_path, 'weights.best_triplet7200.h5'))\n",
    "acc_triplet = test_one_shot_triplet(100, data_type='evaluation')\n",
    "print(acc_triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VOr1CuMv6Cqx"
   },
   "outputs": [],
   "source": [
    "model_triplet.predict(batch_triplet_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BV_H44oZoisw"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, \"Evaluation_full.pickle\"), \"rb\") as f:\n",
    "    (X_eval_train, name_evaluation_full) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1569886803148,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "4LrEDiGkpNir",
    "outputId": "2b2e60a2-1908-4034-cfec-9a56c51c6293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(659, 20, 105, 105, 1)\n"
     ]
    }
   ],
   "source": [
    "X_eval_train = np.expand_dims(X_eval_train, axis=-1)\n",
    "print(X_eval_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-k1e-mOEpdPG"
   },
   "outputs": [],
   "source": [
    "def generateOneTrial_full(data_type = \"evaluation\"):\n",
    "    if (data_type=='train'):\n",
    "        X = X_train\n",
    "        name_class = name_train\n",
    "    if (data_type=='evaluation'):\n",
    "        X = X_eval_train\n",
    "        name_class = name_evaluation_full  \n",
    "    if (data_type=='hyper1'):\n",
    "        X = X_hyper1\n",
    "        name_class = name_hyper1\n",
    "    if (data_type=='hyper2'):\n",
    "        X = X_hyper2\n",
    "        name_class = name_hyper2\n",
    "     \n",
    "    data = []\n",
    "    len_alpha = X.shape[0]  # Number of characters in training set   \n",
    "    characters = np.random.choice(len_alpha, size =2, replace = False) # Choose randomly two distint character in the alphabet\n",
    "    examples = np.random.choice(X.shape[1], size = 2, replace = False) # Choose randomly two distint drawers\n",
    "    img_true = X[characters[0]][examples[0]]\n",
    "    img_positive = X[characters[0]][examples[1]]\n",
    "    img_negative = X[characters[1]][examples[0]]\n",
    "    #data.append([img_true, img_positive, img_negative]) \n",
    "    data.append(img_true)\n",
    "    data.append(img_positive)\n",
    "    data.append(img_negative)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBirnsrBrmQf"
   },
   "outputs": [],
   "source": [
    "data_full = generateOneTrial_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGdRUKN9r2Kd"
   },
   "outputs": [],
   "source": [
    "def generate_one_shot_evaluation_full(N_way=20, data_type = \"evaluation\"):\n",
    "    if (data_type == \"train\"):\n",
    "      X = X_train\n",
    "    else:\n",
    "      X = X_eval_train\n",
    "    len_characters = X.shape[0]\n",
    "    characters = np.random.choice(len_characters, size=N_way, replace = False) # Choose N_way distint characters in the alphabet\n",
    "    len_example = X.shape[1] # Number of examples for each character\n",
    "    examples = np.random.choice(len_example, size = 2, replace = False) # Choose randomly two distint drawers\n",
    "    train_img = []\n",
    "    test_img = []\n",
    "    for i in range(N_way):\n",
    "        test_img.append(X[characters[i]][examples[0]])\n",
    "        train_img.append(X[characters[i]][examples[1]])\n",
    "    test_img = np.array(test_img)\n",
    "    train_img = np.array(train_img)\n",
    "    return test_img, train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1569886817402,
     "user": {
      "displayName": "Thai Hoang Hiep Nguyen",
      "photoUrl": "",
      "userId": "01886901060167918280"
     },
     "user_tz": -120
    },
    "id": "NhgUB1ovuQ-Y",
    "outputId": "b545f731-2129-4179-c777-32b89ce611e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 105, 105, 1)\n",
      "(20, 105, 105, 1)\n"
     ]
    }
   ],
   "source": [
    "test_img, train_img = generate_one_shot_evaluation_full()\n",
    "print(test_img.shape)\n",
    "print(train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXn49kaBu0k-"
   },
   "outputs": [],
   "source": [
    "def test_one_shot_triplet_full(iteration, N_way = 20, data_type = 'evaluation'):\n",
    "    n_accuracy = 0\n",
    "    for i in range(iteration):\n",
    "        test_img, train_img = generate_one_shot_evaluation_full(N_way, data_type)\n",
    "        for k in range(N_way):\n",
    "            test_image_N_way = np.array([test_img[k] for m in range(N_way)])\n",
    "            data_train = [train_img, test_image_N_way, train_img]\n",
    "            predict_value = model_triplet.predict(data_train)\n",
    "            if (k==np.argmin(predict_value)):\n",
    "              n_accuracy+=1              \n",
    "    accuracy = n_accuracy/(iteration*N_way)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBWugi3PvUfg"
   },
   "outputs": [],
   "source": [
    "loss = test_one_shot_triplet_full(50, N_way=600)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Siamese_fellowship.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}